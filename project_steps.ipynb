{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5369eb7-983d-4f59-b328-44c1734896c5",
   "metadata": {},
   "source": [
    "## Kidney disease classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aebe0c1-02c4-4db6-b3c1-84f4aeccc9f4",
   "metadata": {},
   "source": [
    "1. Github Repository Setup\n",
    "2. Project Template Creation\n",
    "3. project Setup & Requirements installation\n",
    "4. Logging ,Utils & Exception Module\n",
    "5. Project workflows\n",
    "6. All components Notebook Experiments\n",
    "7. All components Modular code implementation\n",
    "8. training Pipeline\n",
    "9. MLflow (MLops Tool) -- For  Experiments tracking & model Registration\n",
    "10. DVC(MLops Tool)  --  For Pipeline Tracking & implementation\n",
    "11. Prediction pipeline & user App creation\n",
    "12. Docker\n",
    "13. Final CI/CD deployment on AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4190c2-04a1-402b-be1c-489905934d45",
   "metadata": {},
   "source": [
    "## What is kidney tumor ?\n",
    "* A kidney tumor is an abnormal growth or mass that develops in the kidney. Kidney tumors can be benign (non-cancerous) or malignant (cancerous)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2674fdee-c867-4243-80e6-9e9515df55db",
   "metadata": {},
   "source": [
    "# 1. Github Repository Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5969cf0-a3ab-4d5a-86b2-490663bcd5b6",
   "metadata": {},
   "source": [
    "# 2. Project Template Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ed0db-b395-427d-8cde-e7066f647560",
   "metadata": {},
   "source": [
    "# 1. step  create `template.py` file in vscode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981e8c9-b295-4ff1-b665-bf0b08611a1e",
   "metadata": {},
   "source": [
    "### template.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdaef62-dcc3-4a66-abb3-1335ee839979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "#logging string\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s]: %(message)s:')\n",
    "\n",
    "project_name = 'cnnClassifier'\n",
    "\n",
    "list_of_files = [\n",
    "    \".github/workflows/.gitkeep\",\n",
    "    f\"src/{project_name}/__init__.py\",\n",
    "    f\"src/{project_name}/components/__init__.py\",\n",
    "    f\"src/{project_name}/utils/__init__.py\",\n",
    "    f\"src/{project_name}/config/__init__.py\",\n",
    "    f\"src/{project_name}/config/configuration.py\",\n",
    "    f\"src/{project_name}/pipeline/__init__.py\",\n",
    "    f\"src/{project_name}/entity/__init__.py\",\n",
    "    f\"src/{project_name}/constants/__init__.py\",\n",
    "    \"config/config.yaml\",\n",
    "    \"dvc.yaml\",\n",
    "    \"params.yaml\",\n",
    "    \"requirements.txt\",\n",
    "    \"setup.py\",\n",
    "    \"research/trials.ipynb\",\n",
    "    \"templates/index.html\"\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "for filepath in list_of_files:\n",
    "    filepath = Path(filepath)\n",
    "    filedir, filename = os.path.split(filepath)\n",
    "\n",
    "\n",
    "    if filedir !=\"\":\n",
    "        os.makedirs(filedir, exist_ok=True)\n",
    "        logging.info(f\"Creating directory; {filedir} for the file: {filename}\")\n",
    "\n",
    "    if (not os.path.exists(filepath)) or (os.path.getsize(filepath) == 0):\n",
    "        with open(filepath, \"w\") as f:\n",
    "            pass\n",
    "            logging.info(f\"Creating empty file: {filepath}\")\n",
    "\n",
    "\n",
    "    else:\n",
    "        logging.info(f\"{filename} is already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5f57a0-20a7-49ee-bc19-61b88c586e16",
   "metadata": {},
   "source": [
    "## run command 'python template.py' in cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d801b57-c287-49a2-90fa-9bf0b89ca04c",
   "metadata": {},
   "source": [
    "## requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52e5c05-62bf-4e79-b0ab-050d9e1fb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow==2.12.0\n",
    "pandas \n",
    "dvc\n",
    "mlflow==2.2.2\n",
    "notebook\n",
    "numpy\n",
    "matplotlib\n",
    "seaborn\n",
    "python-box==6.0.2\n",
    "pyYAML\n",
    "tqdm\n",
    "ensure==1.0.2\n",
    "joblib\n",
    "types-PyYAML\n",
    "scipy\n",
    "Flask\n",
    "Flask-Cors\n",
    "gdown\n",
    "-e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd868620-03bf-4b13-875c-f0b3c7f39715",
   "metadata": {},
   "source": [
    "`setup.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dbc549-fc2f-4343-8762-7cf6aef79fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setuptools\n",
    "\n",
    "with open(\"README.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    long_description = f.read()\n",
    "\n",
    "\n",
    "__version__ = \"0.0.0\"\n",
    "\n",
    "REPO_NAME = \"Kidney-disease-classification\"\n",
    "AUTHOR_USER_NAME = \"hellovisha\"\n",
    "SRC_REPO = \"cnnClassifier\"\n",
    "AUTHOR_EMAIL = \"vishalsinghrawat505@gmail.com\"\n",
    "\n",
    "\n",
    "setuptools.setup(\n",
    "    name=SRC_REPO,\n",
    "    version=__version__,\n",
    "    author=AUTHOR_USER_NAME,\n",
    "    author_email=AUTHOR_EMAIL,\n",
    "    description=\"A small python package for CNN app\",\n",
    "    long_description=long_description,\n",
    "    long_description_content=\"text/markdown\",\n",
    "    url=f\"https://github.com/{AUTHOR_USER_NAME}/{REPO_NAME}\",\n",
    "    project_urls={\n",
    "        \"Bug Tracker\": f\"https://github.com/{AUTHOR_USER_NAME}/{REPO_NAME}/issues\",\n",
    "    },\n",
    "    package_dir={\"\": \"src\"},\n",
    "    packages=setuptools.find_packages(where=\"src\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dba924-641b-4fc9-9332-bb93c2f2fa94",
   "metadata": {},
   "source": [
    "# create virtualenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac42cf3-8f53-493e-b15e-67056a05000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -n myenv python=3.8\n",
    "conda activate myenv\n",
    "python --version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c634a-e246-4617-a7eb-15f9442fe33c",
   "metadata": {},
   "source": [
    "then install `requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d0047-5a73-4e0d-a42a-49083c001784",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa92c089-36ab-4e9a-a091-468bc7eb56ef",
   "metadata": {},
   "source": [
    "# 4 Logging, Exception & Utils Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c0400-ab86-49f0-ac53-d2cc1de39b91",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a74186-a44e-47ee-b6dc-a5944fcc5959",
   "metadata": {},
   "source": [
    "### src/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f5ec0-d1f1-43ae-8d74-788b4bc1f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Importing the os module to interact with the operating system\n",
    "import sys  # Importing the sys module to interact with the Python runtime environment\n",
    "import logging  # Importing the logging module to handle logging\n",
    "\n",
    "# Define the logging format string\n",
    "logging_str = \"[%(asctime)s: %(levelname)s: %(module)s: %(message)s]\"\n",
    "\n",
    "# Define the directory where logs will be stored\n",
    "log_dir = \"logs\"\n",
    "\n",
    "# Define the full file path for the log file\n",
    "log_filepath = os.path.join(log_dir, \"running_logs.log\")\n",
    "\n",
    "# Create the log directory if it doesn't exist\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Configure the logging settings\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level to INFO\n",
    "    format=logging_str,  # Set the logging format\n",
    "\n",
    "    # Define the handlers for logging\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filepath),  # Log to a file\n",
    "        logging.StreamHandler(sys.stdout)  # Also log to standard output (console)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a logger with the name 'cnnClassifierLogger'\n",
    "logger = logging.getLogger(\"cnnClassifierLogger\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb5237-f941-4df9-93ae-fd851a5fa5cf",
   "metadata": {},
   "source": [
    "## create file in project folder main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb9d01-2eb0-4c30-9629-9ddec73430ff",
   "metadata": {},
   "source": [
    "## main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18563beb-1c30-452f-9323-5edf6d937ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cnnClassifier import logger\n",
    "\n",
    "\n",
    "\n",
    "logger.info(\"Welcome to the custom log\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a521b54-9fad-4300-a0ad-7b174b16f003",
   "metadata": {},
   "source": [
    "# Exception "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027eb8eb-9079-424a-a8ad-2a7b32d1e660",
   "metadata": {},
   "source": [
    "### create python file inside utils folder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa5431-1b29-4040-8c7b-0438a8dd5851",
   "metadata": {},
   "source": [
    "# common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e16b003-59df-4d06-b928-1e37761f40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Module to interact with the operating system\n",
    "from box.exceptions import BoxValueError  # Exception handling from the Box library\n",
    "import yaml  # Module to work with YAML files\n",
    "from cnnClassifier import logger  # Importing the logger from the cnnClassifier module\n",
    "import json  # Module to work with JSON files\n",
    "import joblib  # Module to save and load Python objects as binary files\n",
    "from ensure import ensure_annotations  # Decorator to enforce type annotations\n",
    "from box import ConfigBox  # Class to convert dictionaries into objects\n",
    "from pathlib import Path  # Module to work with filesystem paths\n",
    "from typing import Any  # For type hinting\n",
    "import base64  # Module to encode and decode data with Base64\n",
    "\n",
    "@ensure_annotations\n",
    "def read_yaml(path_to_yaml: Path) -> ConfigBox:\n",
    "    \"\"\"Reads YAML file and returns its contents as a ConfigBox.\n",
    "\n",
    "    Args:\n",
    "        path_to_yaml (Path): Path to the YAML file.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the YAML file is empty.\n",
    "        Exception: For other exceptions.\n",
    "\n",
    "    Returns:\n",
    "        ConfigBox: Content of the YAML file as a ConfigBox object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path_to_yaml) as yaml_file:\n",
    "            content = yaml.safe_load(yaml_file)\n",
    "            logger.info(f\"YAML file: {path_to_yaml} loaded successfully\")\n",
    "            return ConfigBox(content)\n",
    "    except BoxValueError:\n",
    "        raise ValueError(\"YAML file is empty\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "@ensure_annotations\n",
    "def create_directories(path_to_directories: list, verbose=True):\n",
    "    \"\"\"Create directories specified in the list.\n",
    "\n",
    "    Args:\n",
    "        path_to_directories (list): List of paths to directories to create.\n",
    "        verbose (bool, optional): If True, log the directory creation. Defaults to True.\n",
    "    \"\"\"\n",
    "    for path in path_to_directories:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        if verbose:\n",
    "            logger.info(f\"Created directory at: {path}\")\n",
    "\n",
    "\n",
    "\n",
    "@ensure_annotations\n",
    "def save_json(path: Path, data: dict):\n",
    "    \"\"\"Save dictionary data to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        path (Path): Path to the JSON file.\n",
    "        data (dict): Data to be saved in the JSON file.\n",
    "    \"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    logger.info(f\"JSON file saved at: {path}\")\n",
    "\n",
    "\n",
    "@ensure_annotations\n",
    "def load_json(path: Path) -> ConfigBox:\n",
    "    \"\"\"Load JSON file data.\n",
    "\n",
    "    Args:\n",
    "        path (Path): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        ConfigBox: Data as class attributes instead of a dictionary.\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        content = json.load(f)\n",
    "    logger.info(f\"JSON file loaded successfully from: {path}\")\n",
    "    return ConfigBox(content)\n",
    "\n",
    "\n",
    "@ensure_annotations\n",
    "def save_bin(data: Any, path: Path):\n",
    "    \"\"\"Save data to a binary file.\n",
    "\n",
    "    Args:\n",
    "        data (Any): Data to be saved as a binary file.\n",
    "        path (Path): Path to the binary file.\n",
    "    \"\"\"\n",
    "    joblib.dump(value=data, filename=path)\n",
    "    logger.info(f\"Binary file saved at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def load_bin(path: Path) -> Any:\n",
    "    \"\"\"Load data from a binary file.\n",
    "\n",
    "    Args:\n",
    "        path (Path): Path to the binary file.\n",
    "\n",
    "    Returns:\n",
    "        Any: Object stored in the file.\n",
    "    \"\"\"\n",
    "    data = joblib.load(path)\n",
    "    logger.info(f\"Binary file loaded from: {path}\")\n",
    "    return data\n",
    "\n",
    "@ensure_annotations\n",
    "def get_size(path: Path) -> str:\n",
    "    \"\"\"Get the size of the file in KB.\n",
    "\n",
    "    Args:\n",
    "        path (Path): Path of the file.\n",
    "\n",
    "    Returns:\n",
    "        str: Size of the file in KB.\n",
    "    \"\"\"\n",
    "    size_in_kb = round(os.path.getsize(path) / 1024)\n",
    "    return f\"~ {size_in_kb} KB\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077027cc-cedb-493e-8927-25036205cb41",
   "metadata": {},
   "source": [
    "# get data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e357868f-ee7b-4c87-98a3-259b23ae84c5",
   "metadata": {},
   "source": [
    "## now open config/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ef4de-f829-4af0-802c-a596f2b170c1",
   "metadata": {},
   "source": [
    "## What is yaml file ?\n",
    "* YAML (YAML Ain't Markup Language) is a human-readable data serialization standard that can be used in conjunction with all programming languages and is often used to write configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb9fca-4f52-44d5-b0c5-26ff25d90e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_root: artifacts\n",
    "\n",
    "\n",
    "data_ingestion:\n",
    "  root_dir: artifacts/data_ingestion\n",
    "  source_URL: https://drive.google.com/file/d/1vlhZ5c7abUKF8xXERIw6m9Te8fW7ohw3/view?usp=sharing\n",
    "  local_data_file: artifacts/data_ingestion/data.zip\n",
    "  unzip_dir: artifacts/data_ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c98c99-0c57-4582-8780-4e491773f274",
   "metadata": {},
   "source": [
    "# Data Ingestion Component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c2936-f981-4872-90d1-6acc17d4b246",
   "metadata": {},
   "source": [
    "create file inside research folder `01_data_ingestion.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968b58ac-0772-46f0-8d65-310d08666e44",
   "metadata": {},
   "source": [
    "## 01_data_ingestion.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee956712-eb7f-4839-93eb-38a056fd4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a3e5f-44ee-4569-b44b-eff35b0e9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf0bb10-2d23-4051-aaed-0efecf79a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa232d6-58db-46ac-a418-21aa4970434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97445253-b41c-4e44-ae9a-f2121595e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66aaed-720b-4d9a-a81b-a772f93aba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cnnClassifier.constants import *\n",
    "from src.cnnClassifier.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa419166-55eb-4940-b860-bb1a3950fc65",
   "metadata": {},
   "source": [
    "`src/cnnClassifier/constants\n",
    "/__init__.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73925593-51dd-4350-9b7a-2c4caa8f10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CONFIG_FILE_PATH = Path(\"config/config.yaml\")\n",
    "PARAMS_FILE_PATH = Path(\"params.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d0c70-c2cd-4543-a6d4-b83d51598c4c",
   "metadata": {},
   "source": [
    "`/research\n",
    "/01_data_ingestion.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36bfb68-b44e-4863-b9b9-ddbdb9238fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir \n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a70943-f176-49a8-aa9e-6f1da4da3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "from cnnClassifier import logger\n",
    "from cnnClassifier.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3434db-eb1b-4fa5-a1f2-49af15bb39e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def download_file(self)-> str:\n",
    "        '''\n",
    "        Fetch data from the url\n",
    "        '''\n",
    "\n",
    "        try: \n",
    "            dataset_url = self.config.source_URL\n",
    "            zip_download_dir = self.config.local_data_file\n",
    "            os.makedirs(\"artifacts/data_ingestion\", exist_ok=True)\n",
    "            logger.info(f\"Downloading data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "            file_id = dataset_url.split(\"/\")[-2]\n",
    "            prefix = 'https://drive.google.com/uc?/export=download&id='\n",
    "            gdown.download(prefix+file_id,zip_download_dir)\n",
    "\n",
    "            logger.info(f\"Downloaded data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    \n",
    "\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac23ad51-c520-4846-8e04-e9b45bf45ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06378b33-bfad-4d4e-abcc-88cf798b80ec",
   "metadata": {},
   "source": [
    "# params.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d0b2b-f01f-43b7-9ef1-0e6a8eebc4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION: True\n",
    "IMAGE_SIZE: [224, 224, 3] # as per VGG 16 model\n",
    "BATCH_SIZE: 16\n",
    "INCLUDE_TOP: False\n",
    "EPOCHS: 1\n",
    "CLASSES: 2\n",
    "WEIGHTS: imagenet\n",
    "LEARNING_RATE: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d751a7a-8321-43a9-b96d-c860f68c99be",
   "metadata": {},
   "source": [
    "# Create config_entity.py file in  entity folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c6121-ec00-438b-bc50-be2656aa66b9",
   "metadata": {},
   "source": [
    "`/src/cnnClassifier/entity\n",
    "/config_entity.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb56a8-8670-493b-bc89-ba328b37f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path\n",
    "\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    params_image_size: list\n",
    "    params_learning_rate: float\n",
    "    params_include_top: bool\n",
    "    params_weights: str\n",
    "    params_classes: int\n",
    "\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b258e5-b426-4dd7-8e4a-b4bf8590948d",
   "metadata": {},
   "source": [
    "`/src/cnnClassifier/config\n",
    "/configuration.py`\n",
    "|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915cbc06-6bd9-4f40-bc6c-8ff6590f19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "import os\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories,save_json\n",
    "from cnnClassifier.entity.config_entity import (DataIngestionConfig,\n",
    "                                                PrepareBaseModelConfig,\n",
    "                                                TrainingConfig,\n",
    "                                                EvaluationConfig)\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir \n",
    "        )\n",
    "\n",
    "        return data_ingestion_config\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        config = self.config.prepare_base_model\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            base_model_path=Path(config.base_model_path),\n",
    "            updated_base_model_path=Path(config.updated_base_model_path),\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_learning_rate=self.params.LEARNING_RATE,\n",
    "            params_include_top=self.params.INCLUDE_TOP,\n",
    "            params_weights=self.params.WEIGHTS,\n",
    "            params_classes=self.params.CLASSES\n",
    "        )\n",
    "\n",
    "        return prepare_base_model_config\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"kidney-ct-scan-image\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config\n",
    "    \n",
    "\n",
    "\n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "            path_of_model=\"artifacts/training/model.h5\",\n",
    "            training_data=\"artifacts/data_ingestion/kidney-ct-scan-image\",\n",
    "            mlflow_uri=\"https://dagshub.com/entbappy/Kidney-Disease-Classification-MLflow-DVC.mlflow\",\n",
    "            all_params=self.params,\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch_size=self.params.BATCH_SIZE\n",
    "        )\n",
    "        return eval_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f003f-0c81-4034-80b4-e962f5a68bad",
   "metadata": {},
   "source": [
    "`src/cnnClassifier/components\n",
    "/data_ingestion.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf838a-120a-4143-ae8d-441e3071a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "from cnnClassifier import logger\n",
    "from cnnClassifier.utils.common import get_size\n",
    "from cnnClassifier.entity.config_entity import (DataIngestionConfig)\n",
    "\n",
    "\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def download_file(self)-> str:\n",
    "        '''\n",
    "        Fetch data from the url\n",
    "        '''\n",
    "\n",
    "        try: \n",
    "            dataset_url = self.config.source_URL\n",
    "            zip_download_dir = self.config.local_data_file\n",
    "            os.makedirs(\"artifacts/data_ingestion\", exist_ok=True)\n",
    "            logger.info(f\"Downloading data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "            file_id = dataset_url.split(\"/\")[-2]\n",
    "            prefix = 'https://drive.google.com/uc?/export=download&id='\n",
    "            gdown.download(prefix+file_id,zip_download_dir)\n",
    "\n",
    "            logger.info(f\"Downloaded data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    \n",
    "\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b72b5e1-8ef1-4305-8be0-2d65a7395741",
   "metadata": {},
   "source": [
    "# create file in pipeline folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548c150-92f1-4668-a190-914219184ca1",
   "metadata": {},
   "source": [
    "`stage_01_data_ingestion.py`\n",
    "\n",
    "`stage_02_prepare_base_model.py`\n",
    "\n",
    "`stage_03_model_training.py`\n",
    "\n",
    "`stage_04_model_evaluation.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88294c68-7abb-40be-bb14-78557bfd0703",
   "metadata": {},
   "source": [
    "`stage_01_data_ingestion.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f2d81-13bd-4105-9a60-38409e77d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cnnClassifier.config.configuration import ConfigurationManager\n",
    "from src.cnnClassifier.components.data_ingestion import DataIngestion\n",
    "from src.cnnClassifier import logger\n",
    " \n",
    "\n",
    "\n",
    "STAGE_NAME = \"Data Ingestion stage\"\n",
    "\n",
    "class DataIngestionTrainingPipeline:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def main(self):\n",
    "        config = ConfigurationManager()\n",
    "        data_ingestion_config = config.get_data_ingestion_config()\n",
    "        data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "        data_ingestion.download_file()\n",
    "        data_ingestion.extract_zip_file()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n",
    "        obj = DataIngestionTrainingPipeline()\n",
    "        obj.main()\n",
    "        logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n",
    "    except Exception as e:\n",
    "        logger.exception(e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba902c2-255f-45af-8af1-28ed8caf2cf1",
   "metadata": {},
   "source": [
    "`main.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207e781-c094-4656-8ecc-c04707d38195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cnnClassifier import logger\n",
    "from src.cnnClassifier.pipeline.stage_01_data_ingestion import DataIngestionTrainingPipeline\n",
    "\n",
    "\n",
    "\n",
    "STAGE_NAME = \"Data Ingestion stage\"\n",
    "try:\n",
    "   logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\") \n",
    "   data_ingestion = DataIngestionTrainingPipeline()\n",
    "   data_ingestion.main()\n",
    "   logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n",
    "except Exception as e:\n",
    "        logger.exception(e)\n",
    "        raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7461cc-18cf-44fe-baa5-5e3eae9a5099",
   "metadata": {},
   "source": [
    "run `python main.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f1225f-c316-480b-8d3a-ec4d2074568e",
   "metadata": {},
   "source": [
    " ## Prepare Base Model Component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d9146c-2a83-4193-990a-ce3d5e742301",
   "metadata": {},
   "source": [
    "`config/config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13ea25-8f75-4703-a999-e82d336b6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_root: artifacts\n",
    "\n",
    "\n",
    "data_ingestion:\n",
    "  root_dir: artifacts/data_ingestion\n",
    "  source_URL: https://drive.google.com/file/d/1WZxRoYGZKgOnd2zPgK6Whrec4ULNfI_z/view?usp=sharing\n",
    "  local_data_file: artifacts/data_ingestion/data.zip\n",
    "  unzip_dir: artifacts/data_ingestion\n",
    "\n",
    "\n",
    "\n",
    "prepare_base_model:\n",
    "  root_dir: artifacts/prepare_base_model\n",
    "  base_model_path: artifacts/prepare_base_model/base_model.h5\n",
    "  updated_base_model_path: artifacts/prepare_base_model/base_model_updated.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3afe4b-af00-4aa6-b43e-e9d87b026bed",
   "metadata": {},
   "source": [
    "`params.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25934c5-93a3-426d-9ddf-265ca4e10b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION: True\n",
    "IMAGE_SIZE: [224, 224, 3] # as per VGG 16 model\n",
    "BATCH_SIZE: 16\n",
    "INCLUDE_TOP: False\n",
    "EPOCHS: 1\n",
    "CLASSES: 2\n",
    "WEIGHTS: imagenet\n",
    "LEARNING_RATE: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343af760-dd46-45b7-92bf-5fdf4d34e5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
